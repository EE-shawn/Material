## 论文
- [Parallel Multi Channel Convolution using General Matrix Multiplication](https://arxiv.org/abs/1704.04428)
- [Exploring Sparsity in Recurrent Neural Networks](https://arxiv.org/abs/1704.05119)
- [Weight normalization ]()[[Pytouch]](https://github.com/ruotianluo/weightnorm-pytorch)  
- [Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models](https://arxiv.org/abs/1702.03275) [[keras]](https://github.com/titu1994/BatchRenormalization)
- [PathNet: Evolution Channels Gradient Descent in Super Neural Networks](https://arxiv.org/abs/1701.08734) [[tensorflow]](https://github.com/jaesik817/pathnet) [[pytorch]](https://github.com/kimhc6028/pathnet-pytorch)
- [A Feature Embedding Strategy for High-level CNN representations from Multiple ConvNets](https://arxiv.org/abs/1705.04301)
- [Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations](https://arxiv.org/abs/1606.01305) [[tensorflow]](https://github.com/tam17aki/zoneout-tensorflow)
- [Must-read papers on network representation learning (NRL)/network embedding (NE)](https://github.com/thunlp/NRLpapers)
- [Detecting Statistical Interactions from Neural Network Weights](https://arxiv.org/abs/1705.04977)
- [Deep Mutual Learning](https://arxiv.org/abs/1706.00384)
- [Distributed Sequence Memory of Multidimensional Inputs in Recurrent Networks](http://www.jmlr.org/papers/v18/16-270.html)
- [Forward Thinking: Building and Training Neural Networks One Layer at a Time](https://arxiv.org/abs/1706.02480) [[code]](https://github.com/tkchris93/ForwardThinking) [[pytorch]](https://github.com/kimhc6028/forward-thinking-pytorch)

## 资料
- [为什么 LSTM 在参数初始化时要使用 SVD 方法使参数正交？ - 知乎](https://www.zhihu.com/question/37686246)
- [Krizhevsky是怎么想到在CNN里用Dropout和ReLu的?](https://www.zhihu.com/question/28720729)
- [Picasso：免费开源的CNN可视化工具](https://github.com/merantix/picasso)
- [神经网络能解决所有问题吗？](https://yq.aliyun.com/articles/81163)
- [Reducing Reparameterization Gradient Variance](https://arxiv.org/abs/1705.07880) [code](https://github.com/andymiller/ReducedVarianceReparamGradients)
- [Recurrent Additive Networks](https://arxiv.org/abs/1705.07393)
- [深度学习多任务学习综述](http://sebastianruder.com/multi-task/index.html)
- [如何让深度学习在手机应用上也能加速跑？](https://mp.weixin.qq.com/s?__biz=MzI0ODcxODk5OA==&mid=2247485767&idx=1&sn=96e27730061741fa87f86428efb188f3)
- [为什么 Non-Convex Optimization 受到了越来越大的关注？](https://www.zhihu.com/question/61034915)
- [RNN Training Tips and Tricks](https://github.com/karpathy/char-rnn#tips-and-tricks)
