## 论文
- [Parallel Multi Channel Convolution using General Matrix Multiplication](https://arxiv.org/abs/1704.04428)
- [Exploring Sparsity in Recurrent Neural Networks](https://arxiv.org/abs/1704.05119)
- [Weight normalization ]()[[Pytouch]](https://github.com/ruotianluo/weightnorm-pytorch)  
- [Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models](https://arxiv.org/abs/1702.03275) [[keras]](https://github.com/titu1994/BatchRenormalization)
- [PathNet: Evolution Channels Gradient Descent in Super Neural Networks](https://arxiv.org/abs/1701.08734) [[tensorflow]](https://github.com/jaesik817/pathnet) [[pytorch]](https://github.com/kimhc6028/pathnet-pytorch)
- [A Feature Embedding Strategy for High-level CNN representations from Multiple ConvNets](https://arxiv.org/abs/1705.04301)
- [Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations](https://arxiv.org/abs/1606.01305) [[tensorflow]](https://github.com/tam17aki/zoneout-tensorflow)
- [Must-read papers on network representation learning (NRL)/network embedding (NE)](https://github.com/thunlp/NRLpapers)
- [Detecting Statistical Interactions from Neural Network Weights](https://arxiv.org/abs/1705.04977)
- [Deep Mutual Learning](https://arxiv.org/abs/1706.00384)

## 资料
- [为什么 LSTM 在参数初始化时要使用 SVD 方法使参数正交？ - 知乎](https://www.zhihu.com/question/37686246)
- [Krizhevsky是怎么想到在CNN里用Dropout和ReLu的?](https://www.zhihu.com/question/28720729)
- [Picasso：免费开源的CNN可视化工具](https://github.com/merantix/picasso)
- [神经网络能解决所有问题吗？](https://yq.aliyun.com/articles/81163)
- [Reducing Reparameterization Gradient Variance](https://arxiv.org/abs/1705.07880) [code](https://github.com/andymiller/ReducedVarianceReparamGradients)
- [Recurrent Additive Networks](https://arxiv.org/abs/1705.07393)
- [深度学习多任务学习综述](http://sebastianruder.com/multi-task/index.html)
